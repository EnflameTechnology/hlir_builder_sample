


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Client Operation Semantics &mdash; HLIR Builder master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/client_operation_semantics.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/cpp_theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/collapsible-lists/css/tree_view.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="TopsGraph Compiler" href="tops_graph_compiler.html" />
    <link rel="prev" title="Meta Operation Semantics" href="meta_operation_semantics.html" />
  <!-- Google Analytics -->
  
  <!-- End Google Analytics -->
  

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <!--a class="header-logo" href="https://www.enflame-tech.com" aria-label="Builder"></a> -->
      <a class="header-logo" aria-label="Builder"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a class="reference internal" href="get_started.html">Get Started</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Operation Semantics
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="meta_operation_semantics.html">
                  <span class="dropdown-title">Meta Ops</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="client_operation_semantics.html">
                  <span class="dropdown-title">Client Ops</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <a class="reference internal" href="api/library_root.html">C++ API</a>
          </li>

          <li>
            <!--<a href="https://www.enflame-tech.com">Python API</a> -->
            <a>Python API</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Tutorials
              </a>
              <div class="resources-dropdown-menu">
                <!--<a class="doc-dropdown-option nav-dropdown-item" href="https://www.enflame-tech.com"> -->
                <a class="doc-dropdown-option nav-dropdown-item">
                  <span class="dropdown-title">Inference</span>
                  <p></p>
                </a>
                <!--<a class="doc-dropdown-option nav-dropdown-item" href="https://www.enflame-tech.com"> -->
                <a class="doc-dropdown-option nav-dropdown-item">
                  <span class="dropdown-title">Trainning</span>
                  <p></p>
                </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  master
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="get_started.html">Get Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="meta_operation_semantics.html">Meta Operation Semantics</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Client Operation Semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="tops_graph_compiler.html">TopsGraph Compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/library_root.html">C++ API</a></li>
</ul>
<p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/version.html">Version</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Client Operation Semantics</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/client_operation_semantics.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="client-operation-semantics">
<h1>Client Operation Semantics<a class="headerlink" href="#client-operation-semantics" title="Permalink to this headline">¶</a></h1>
<p>The following describes the semantics of client operations defined in the HLIR Builder interface.</p>
<div class="section" id="argmax">
<h2>ArgMax<a class="headerlink" href="#argmax" title="Permalink to this headline">¶</a></h2>
<p>Computes the indices of the max elements of the input tensor’s element along the provided <span class="math notranslate nohighlight">\(axis\)</span>. The resulting tensor has the same rank as the input if <span class="math notranslate nohighlight">\(keepdims\)</span> equals 1.
If <span class="math notranslate nohighlight">\(keepdims\)</span> equals 0, then the resulting tensor has the reduced dimension pruned. If <span class="math notranslate nohighlight">\(select\_last\_index\)</span> is True (default False), the index of the last occurrence of the max is selected if the max appears more than once in the input. Otherwise the index of the first occurrence is selected. The type of the output tensor is integer.</p>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is an op whose result shape is <span class="math notranslate nohighlight">\((*)\)</span>, where <span class="math notranslate nohighlight">\(*\)</span> means any number of dimensions.</p></li>
</ul>
</dd>
<dt><strong>Parameters:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(axis\)</span> is the dimension in which to compute the arg indices. Accepted range is <span class="math notranslate nohighlight">\([-R, R)\)</span>, where <span class="math notranslate nohighlight">\(R\)</span> is <span class="math notranslate nohighlight">\(Rank(x)\)</span>. Default: 0.</p></li>
<li><p><span class="math notranslate nohighlight">\(keepdims\)</span> Keep the reduced dimension or not, default 1 means keep reduced dimension. Default: 1.</p></li>
<li><p><span class="math notranslate nohighlight">\(select\_last\_index\)</span> Whether to select the last index or the first index if the {name} appears in multiple indices. Default: False (first index).</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(reduced\_indices\)</span> is the reduced indices op with data type int64.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                 <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">ArgMax</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">select_last_index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [0, 1, 1], dtype=np.int64</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="argmin">
<h2>ArgMin<a class="headerlink" href="#argmin" title="Permalink to this headline">¶</a></h2>
<p>Computes the indices of the min elements of the input tensor’s element along the provided <span class="math notranslate nohighlight">\(axis\)</span>. The resulting tensor has the same rank as the input if <span class="math notranslate nohighlight">\(keepdims\)</span> equals 1.
If <span class="math notranslate nohighlight">\(keepdims\)</span> equals 0, then the resulting tensor has the reduced dimension pruned. If <span class="math notranslate nohighlight">\(select\_last\_index\)</span> is True (default False), the index of the last occurrence of the min is selected if the min appears more than once in the input. Otherwise the index of the first occurrence is selected. The type of the output tensor is integer.</p>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is an op whose result shape is <span class="math notranslate nohighlight">\((*)\)</span>, where <span class="math notranslate nohighlight">\(*\)</span> means any number of dimensions.</p></li>
</ul>
</dd>
<dt><strong>Parameters:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(axis\)</span> is the dimension in which to compute the arg indices. Accepted range is <span class="math notranslate nohighlight">\([-R, R)\)</span>, where <span class="math notranslate nohighlight">\(R\)</span> is <span class="math notranslate nohighlight">\(Rank(x)\)</span>. Default: 0.</p></li>
<li><p><span class="math notranslate nohighlight">\(keepdims\)</span> Keep the reduced dimension or not, default 1 means keep reduced dimension. Default: 1.</p></li>
<li><p><span class="math notranslate nohighlight">\(select\_last\_index\)</span> Whether to select the last index or the first index if the {name} appears in multiple indices. Default: False (first index).</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(reduced\_indices\)</span> is the reduced indices op with data type int64.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                 <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">ArgMin</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">select_last_index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [1, 0, 0], dtype=np.int64</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="argsort">
<h2>ArgSort<a class="headerlink" href="#argsort" title="Permalink to this headline">¶</a></h2>
<p>Returns the indices that sort a tensor along a given dimension in the specified order by value. The default sort algorithm is ascending, if you want the sort algorithm to be descending, you must set the <code class="docutils literal notranslate"><span class="pre">descending</span></code> as True.</p>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is an op whose result shape is <span class="math notranslate nohighlight">\((*)\)</span>, where <span class="math notranslate nohighlight">\(*\)</span> means any number of dimensions.</p></li>
</ul>
</dd>
<dt><strong>Parameters:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(axis\)</span> is the dimension to sort along. The effective range is <span class="math notranslate nohighlight">\([-R, R)\)</span>, where <span class="math notranslate nohighlight">\(R\)</span> is <span class="math notranslate nohighlight">\(Rank(x)\)</span>. Default: 0.</p></li>
<li><p><span class="math notranslate nohighlight">\(descending\)</span> controls the sorting order (ascending or descending). Default: false.</p></li>
<li><p><span class="math notranslate nohighlight">\(only\_return\_indices\)</span> if true, will return the sorted indices only. Otherwise, will return both the sorted data and indices. Default: true.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(sorted\_indices\)</span> is an op with the same shape as <span class="math notranslate nohighlight">\(x\)</span> and with data type int64.</p></li>
<li><p><span class="math notranslate nohighlight">\(sorted\_data\)</span> is an op with the same shape and data type as <span class="math notranslate nohighlight">\(x\)</span>. Optional, will not be present when <span class="math notranslate nohighlight">\(only\_return\_indices\)</span> is true.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                  <span class="p">[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                  <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">ArgSort</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [[[2, 1, 0, 3],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#           [3, 1, 2, 0],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#           [1, 3, 0, 2]]], dtype=np.int64</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="conv2d">
<h2>Conv2D<a class="headerlink" href="#conv2d" title="Permalink to this headline">¶</a></h2>
<p>Applies a 2D convolution over an input signal composed of several input planes.</p>
<p>In the simplest case for layout of “NCHW”, the output value of the layer with input size <span class="math notranslate nohighlight">\(\left ( N,C_{in},H_{in},W_{in} \right )\)</span> and output <span class="math notranslate nohighlight">\(\left ( N,C_{out},H_{out},W_{out} \right )\)</span> can be precisely described as:</p>
<div class="math notranslate nohighlight">
\[output\left ( N_{i},C_{out_{j}} \right )=bias\left (C_{out_{j}}  \right )+\sum_{k=0}^{C_{in}-1}kernel\left ( C_{out_{j}},k \right ) \bigstar input\left ( N_{i},k \right )\]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}H_{out}=\left \lfloor \frac{H_{in}+padding\left [ 0 \right ]+padding\left [ 1 \right ]-dilation\left [ 0 \right ]\times \left ( H_{kernel}-1 \right )-1}{b}+1\right \rfloor\\W_{out}=\left \lfloor \frac{W_{in}+padding\left [ 2 \right ]+padding\left [ 3 \right ]-dilation\left [ 1 \right ]\times \left ( W_{kernel}-1 \right )-1}{b}+1\right \rfloor\end{aligned}\end{align} \]</div>
<p>where <span class="math notranslate nohighlight">\(\bigstar\)</span> is the valid 2D <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a> operator, <span class="math notranslate nohighlight">\(N\)</span> is a batch size, <span class="math notranslate nohighlight">\(C\)</span> denotes a number of channels, <span class="math notranslate nohighlight">\(H\)</span> is a height in pixels, and <span class="math notranslate nohighlight">\(W\)</span> is width in pixels.</p>
<p>The first introduction can be found in paper <a class="reference external" href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf">Gradient Based Learning Applied to Document Recognition</a>. More detailed introduction can be found <a class="reference external" href="http://cs231n.github.io/convolutional-networks/">here</a>.</p>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(input\)</span> is an op whose result shape is of 4D. Shape is <span class="math notranslate nohighlight">\(\left ( N,C_{in},H_{in},W_{in} \right )\)</span> for layout of “NCHW” and <span class="math notranslate nohighlight">\(\left ( N,H_{in},W_{in},C_{in} \right )\)</span> for “NHWC”. Required.</p></li>
<li><p><span class="math notranslate nohighlight">\(kernel\)</span> is an op whose result shape is of 4D. Shape is <span class="math notranslate nohighlight">\(\left ( C_{out},C_{in},H_{kernel},W_{kernel} \right )\)</span> for layout of “NCHW” and <span class="math notranslate nohighlight">\(\left ( H_{kernel},W_{kernel},C_{in},C_{out} \right )\)</span> for “NHWC”. Required.</p></li>
<li><p><span class="math notranslate nohighlight">\(bias\)</span> is an op whose result shape is 1D, <span class="math notranslate nohighlight">\(\left ( C_{out} \right )\)</span>. Optional.</p></li>
</ul>
</dd>
<dt><strong>Parameters:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(group\)</span> is number of blocked connections from input channels to output channels. Default: 1.</p></li>
<li><p><span class="math notranslate nohighlight">\(auto\_pad\)</span> is a string for automatically padding. If it sets as the default value, explicit padding is used. Default: “NOTSET”.</p></li>
<li><p><span class="math notranslate nohighlight">\(layout\)</span> is a string for data format, “NCHW” or “NHWC”. Default: “NHWC”.</p></li>
<li><p><span class="math notranslate nohighlight">\(stride\)</span> is the stride of the sliding window for each dimension of input. Size is 2 for both <span class="math notranslate nohighlight">\(H_{in}\)</span> and <span class="math notranslate nohighlight">\(W_{in}\)</span>. Default: [1, 1].</p></li>
<li><p><span class="math notranslate nohighlight">\(padding\)</span> specifies the amount of zero padding to be applied to the base area. Size is 4 for <span class="math notranslate nohighlight">\(\left [ top,bottom,left,right \right ]\)</span>. Default: [0, 0, 0, 0].</p></li>
<li><p><span class="math notranslate nohighlight">\(dilation\)</span> controls the spacing between the kernel points; also known as the atrous algorithm. It is harder to describe, but this <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what dilation does. Size is 2 for both <span class="math notranslate nohighlight">\(H_{kernel}\)</span> and <span class="math notranslate nohighlight">\(W_{kernel}\)</span>. Default: [1, 1].</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> of convolution with shape of <span class="math notranslate nohighlight">\(\left ( N,C_{out},H_{out},W_{out} \right )\)</span> for layout of “NCHW” and <span class="math notranslate nohighlight">\(\left ( N,H_{out},W_{out},C_{out} \right )\)</span> for “NHWC”.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kernel_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bias_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kernel</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">kernel_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bias</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">bias_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">bias</span><span class="p">],</span> <span class="c1"># inputs are put in a list</span>
<span class="gp">&gt;&gt;&gt; </span>                   <span class="n">group</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                   <span class="n">layout</span><span class="o">=</span><span class="s2">&quot;NHWC&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                   <span class="n">stride</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                   <span class="n">padding</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="conv2dtranspose">
<h2>Conv2DTranspose<a class="headerlink" href="#conv2dtranspose" title="Permalink to this headline">¶</a></h2>
<p>Applies a 2D transposed convolution operator over an input image composed of several input planes.</p>
<p>This module can be seen as the gradient of Conv2D with respect to its input. It is also known as a fractionally-strided convolution or a deconvolution (although it is not an actual deconvolution operation as it does not compute a true inverse of convolution). Actually it is implemented by Conv2D with new calculated <span class="math notranslate nohighlight">\(stride\)</span>, <span class="math notranslate nohighlight">\(padding\)</span> and <span class="math notranslate nohighlight">\(dilation\)</span> instead of the ones in parameters.</p>
<div class="math notranslate nohighlight">
\[output\left ( N_{i},C_{out_{j}} \right )=bias\left (C_{out_{j}}  \right )+\sum_{k=0}^{C_{in}-1}kernel\left ( C_{out_{j}},k \right ) \bigstar input\left ( N_{i},k \right )\]</div>
<p>where <span class="math notranslate nohighlight">\(\bigstar\)</span> is the valid 2D <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a> operator, <span class="math notranslate nohighlight">\(N\)</span> is a batch size, <span class="math notranslate nohighlight">\(C\)</span> denotes a number of channels, <span class="math notranslate nohighlight">\(H\)</span> is a height in pixels, and <span class="math notranslate nohighlight">\(W\)</span> is width in pixels.</p>
<p>If the padding parameter is provided the shape of the output is calculated via the following equation:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}H_{out}=stride[0]\times \left ( H_{in}-1 \right )+output\_padding[0]+\left ( \left ( H_{kernel}-1 \right ) \times dilation[0]+1\right )-padding[0]-padding[1]\\W_{out}=stride[1]\times \left ( W_{in}-1 \right )+output\_padding[1]+\left ( \left ( W_{kernel}-1 \right ) \times dilation[1]+1\right )-padding[2]-padding[3]\end{aligned}\end{align} \]</div>
<p>For more information, see the visualizations <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">here</a> and <a class="reference external" href="https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf">Deconvolutional Networks</a>.</p>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(input\)</span> is an op whose result shape is of 4D. Shape is <span class="math notranslate nohighlight">\(\left ( N,C_{in},H_{in},W_{in} \right )\)</span> for layout of “NCHW” and <span class="math notranslate nohighlight">\(\left ( N,H_{in},W_{in},C_{in} \right )\)</span> for “NHWC”. Required.</p></li>
<li><p><span class="math notranslate nohighlight">\(kernel\)</span> is an op whose result shape is of 4D. Shape is <span class="math notranslate nohighlight">\(\left ( C_{in},C_{out},H_{kernel},W_{kernel} \right )\)</span> for layout of “NCHW” and <span class="math notranslate nohighlight">\(\left ( H_{kernel},W_{kernel},C_{out},C_{in} \right )\)</span> for “NHWC”. Required.</p></li>
<li><p><span class="math notranslate nohighlight">\(bias\)</span> is an op whose result shape is 1D, <span class="math notranslate nohighlight">\(\left ( C_{out} \right )\)</span>. Optional.</p></li>
</ul>
</dd>
<dt><strong>Parameters:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(group\)</span> is number of blocked connections from input channels to output channels. Default: 1.</p></li>
<li><p><span class="math notranslate nohighlight">\(auto\_pad\)</span> is a string for automatically padding. If it sets as the default value, explicit padding is used. Default: “NOTSET”.</p></li>
<li><p><span class="math notranslate nohighlight">\(layout\)</span> is a string for data format, “NCHW” or “NHWC”. Default: “NHWC”.</p></li>
<li><p><span class="math notranslate nohighlight">\(stride\)</span> is the stride of the sliding window for each dimension of input. Size is 2 for both <span class="math notranslate nohighlight">\(H_{in}\)</span> and <span class="math notranslate nohighlight">\(W_{in}\)</span>. Default: [1, 1].</p></li>
<li><p><span class="math notranslate nohighlight">\(padding\)</span> specifies the amount of zero padding to be applied to the base area. Size is 4 for <span class="math notranslate nohighlight">\(\left [ top,bottom,left,right \right ]\)</span>. Default: [0, 0, 0, 0].</p></li>
<li><p><span class="math notranslate nohighlight">\(output\_padding\)</span> is additional size added to one side of spatial dimensions. Size is 2 for <span class="math notranslate nohighlight">\(\left [ bottom,right \right ]\)</span>. Default: [0, 0].</p></li>
<li><p><span class="math notranslate nohighlight">\(dilation\)</span> controls the spacing between the kernel points; also known as the atrous algorithm. It is harder to describe, but this <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what dilation does. Size is 2 for both <span class="math notranslate nohighlight">\(H_{kernel}\)</span> and <span class="math notranslate nohighlight">\(W_{kernel}\)</span>. Default: [1, 1].</p></li>
<li><p><span class="math notranslate nohighlight">\(output\_shape\)</span> can be explicitly set which will cause padding values to be auto generated. If output_shape is specified padding values are ignored. It should be size of 4 or empty. Default: [].</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> of convolution with shape of <span class="math notranslate nohighlight">\(\left ( N,C_{out},H_{out},W_{out} \right )\)</span> for layout of “NCHW” and <span class="math notranslate nohighlight">\(\left ( N,H_{out},W_{out},C_{out} \right )\)</span> for “NHWC”.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kernel_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bias_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kernel</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">kernel_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bias</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">bias_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Conv2DTranspose</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">bias</span><span class="p">],</span> <span class="c1"># inputs are put in a list</span>
<span class="gp">&gt;&gt;&gt; </span>                            <span class="n">group</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                            <span class="n">layout</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                            <span class="n">stride</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                            <span class="n">padding</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                            <span class="n">output_padding</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># output shape should be [1, 1, 6, 6]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="equal">
<h2>Equal<a class="headerlink" href="#equal" title="Permalink to this headline">¶</a></h2>
<p>Returns the truth value of (x == y) element-wise.</p>
<p>It supports Numpy-style broadcasting, for more details please check the <a class="reference external" href="https://numpy.org/doc/stable/user/basics.broadcasting.html">doc</a>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}equal(x_{i}, y_{i})=\begin{cases}
true &amp; \text{ if } x_{i}=y_{i} \\
false &amp; \text{ if } x_{i}\neq y_{i}
\end{cases}\end{split}\]</div>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is the first input op.</p></li>
<li><p><span class="math notranslate nohighlight">\(y\)</span> is the second input op.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with broadcasting shape of the inputs and data type of bool.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">x_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [True, False, False]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="flatten">
<h2>Flatten<a class="headerlink" href="#flatten" title="Permalink to this headline">¶</a></h2>
<p>Flattens a contiguous range of dims into a tensor.</p>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is an op whose result shape is <span class="math notranslate nohighlight">\((*)\)</span>, where <span class="math notranslate nohighlight">\(*\)</span> means any number of dimensions.</p></li>
</ul>
</dd>
<dt><strong>Parameters:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(start\_dim\)</span> is the start of the range to be flatten If <span class="math notranslate nohighlight">\(start\_dim &lt; 0\)</span>, then <span class="math notranslate nohighlight">\(start\_dim\)</span> will become <span class="math notranslate nohighlight">\(start\_dim + Rank(x)\)</span>. Default: 1.</p></li>
<li><p><span class="math notranslate nohighlight">\(end\_dim\)</span> is the end of the range to be flatten. If <span class="math notranslate nohighlight">\(end\_dim &lt; 0\)</span>, then <span class="math notranslate nohighlight">\(end\_dim\)</span> will become <span class="math notranslate nohighlight">\(end\_dim + Rank(x)\)</span>. Default: -1.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with the flattened shape and the same data type of the input.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># shape : [2, 2, 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># shape : [2, 4]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result : [[1, 2, 3, 4],[5, 6, 7, 8]]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="greater">
<h2>Greater<a class="headerlink" href="#greater" title="Permalink to this headline">¶</a></h2>
<p>Returns the truth value of (x &gt; y) element-wise.</p>
<p>It supports Numpy-style broadcasting, for more details please check the <a class="reference external" href="https://numpy.org/doc/stable/user/basics.broadcasting.html">doc</a>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}greater(x_{i}, y_{i})=\begin{cases}
true &amp; \text{ if } x_{i}&gt; y_{i} \\
false &amp; \text{ if } x_{i}\leq y_{i}
\end{cases}\end{split}\]</div>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is the first input op.</p></li>
<li><p><span class="math notranslate nohighlight">\(y\)</span> is the second input op.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with broadcasting shape of the inputs and data type of bool.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">x_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Greater</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [False, False, True]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="greaterequal">
<h2>GreaterEqual<a class="headerlink" href="#greaterequal" title="Permalink to this headline">¶</a></h2>
<p>Returns the truth value of (x &gt;= y) element-wise.</p>
<p>It supports Numpy-style broadcasting, for more details please check the <a class="reference external" href="https://numpy.org/doc/stable/user/basics.broadcasting.html">doc</a>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}greater\_equal(x_{i}, y_{i})=\begin{cases}
true &amp; \text{ if } x_{i}\geq  y_{i} \\
false &amp; \text{ if } x_{i}&lt; y_{i}
\end{cases}\end{split}\]</div>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is the first input op.</p></li>
<li><p><span class="math notranslate nohighlight">\(y\)</span> is the second input op.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with broadcasting shape of the inputs and data type of bool.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">x_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">GreaterEqual</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [True, False, True]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="hardsigmoid">
<h2>HardSigmoid<a class="headerlink" href="#hardsigmoid" title="Permalink to this headline">¶</a></h2>
<p>Applies the hard sigmoid function element-wise.</p>
<p>A 3-part piecewise linear approximation of sigmoid, which is much faster than sigmoid. For more details please refer to this <a class="reference external" href="https://arxiv.org/abs/1603.00391">link</a>.
By default, <span class="math notranslate nohighlight">\(slope=\frac{1}{6}\)</span> and <span class="math notranslate nohighlight">\(offset=\frac{1}{2}\)</span>. The formula is</p>
<div class="math notranslate nohighlight">
\[\begin{split}hard\_sigmoid\left ( x \right )=\left\{\begin{matrix}
0, &amp; x\leq -3 \\
1, &amp; x\geq 3 \\
\frac{1}{6}\times x+\frac{1}{2}, &amp; otherwise \\
\end{matrix}\right.\end{split}\]</div>
<p>While in the general case, the formula is</p>
<div class="math notranslate nohighlight">
\[\begin{split}hard\_sigmoid\left ( x \right )=\left\{\begin{matrix}
0, &amp; x\leq -\frac{offset}{slope} \\
1, &amp; x\geq \frac{1-offset}{slope} \\
slope\times x+offset, &amp; otherwise \\
\end{matrix}\right.\end{split}\]</div>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is an op whose result shape is <span class="math notranslate nohighlight">\((*)\)</span>, where <span class="math notranslate nohighlight">\(*\)</span> means any number of dimensions.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with shape of <span class="math notranslate nohighlight">\((*)\)</span>, same as the input.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">hard_sigmoid</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1"># [0., 1, 0.666667]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="hardswish">
<h2>HardSwish<a class="headerlink" href="#hardswish" title="Permalink to this headline">¶</a></h2>
<p>Applies the hard swish function element-wise.</p>
<p>A 3-part piecewise linear approximation of swish, which performs better in computational stability and efficiency compared to swish function. For more details please refer to this <a class="reference external" href="https://arxiv.org/pdf/1905.02244.pdf">link</a>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}hard\_swish\left ( x \right )=\left\{\begin{matrix}
0, &amp; x\leq -3 \\
1, &amp; x\geq 3 \\
\frac{x\left ( x+3 \right )}{6}, &amp; otherwise \\
\end{matrix}\right.\end{split}\]</div>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is an op whose result shape is <span class="math notranslate nohighlight">\((*)\)</span>, where <span class="math notranslate nohighlight">\(*\)</span> means any number of dimensions.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with shape of <span class="math notranslate nohighlight">\((*)\)</span>, same as the input.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">hard_swish</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1"># [0., 5., 0.666667]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="less">
<h2>Less<a class="headerlink" href="#less" title="Permalink to this headline">¶</a></h2>
<p>Returns the truth value of (x &lt; y) element-wise.</p>
<p>It supports Numpy-style broadcasting, for more details please check the <a class="reference external" href="https://numpy.org/doc/stable/user/basics.broadcasting.html">doc</a>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}less(x_{i}, y_{i})=\begin{cases}
true &amp; \text{ if } x_{i}&lt;  y_{i} \\
false &amp; \text{ if } x_{i}\geq  y_{i}
\end{cases}\end{split}\]</div>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is the first input op.</p></li>
<li><p><span class="math notranslate nohighlight">\(y\)</span> is the second input op.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with broadcasting shape of the inputs and data type of bool.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">x_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Less</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [False, True, False]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="lessequal">
<h2>LessEqual<a class="headerlink" href="#lessequal" title="Permalink to this headline">¶</a></h2>
<p>Returns the truth value of (x &lt;= y) element-wise.</p>
<p>It supports Numpy-style broadcasting, for more details please check the <a class="reference external" href="https://numpy.org/doc/stable/user/basics.broadcasting.html">doc</a>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}less\_equal(x_{i}, y_{i})=\begin{cases}
true &amp; \text{ if } x_{i}\leq   y_{i} \\
false &amp; \text{ if } x_{i}&gt; y_{i}
\end{cases}\end{split}\]</div>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is the first input op.</p></li>
<li><p><span class="math notranslate nohighlight">\(y\)</span> is the second input op.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with broadcasting shape of the inputs and data type of bool.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">x_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">LessEqual</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [True, True, False]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="maxpool2d">
<h2>MaxPool2D<a class="headerlink" href="#maxpool2d" title="Permalink to this headline">¶</a></h2>
<p>Applies a 2D max pooling over an input signal composed of several input planes.</p>
<p>In the simplest case for layout of “NCHW”, the output value of the layer with input size <span class="math notranslate nohighlight">\(\left ( N,C_{in},H_{in},W_{in} \right )\)</span>, output <span class="math notranslate nohighlight">\(\left ( N,C_{out},H_{out},W_{out} \right )\)</span> and ksize <span class="math notranslate nohighlight">\(\left ( H_{kernel},W_{kernel} \right )\)</span> can be precisely described as
.. math:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span>output\left ( N_{i},C_{j},h,w \right )=\underset{m=0,\cdots ,H_{kernel}-1}{max}\underset{n=0,\cdots ,W_{kernel}-1}{max}input\left ( N_{i},C_{j},stride\left [ 0 \right ]\times h+m,stride\left [ 1 \right ]\times w+n \right )
</pre></div>
</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}H_{out}=\left \lfloor \frac{H_{in}+padding\left [ 0 \right ]+padding\left [ 1 \right ]-dilation\left [ 0 \right ]\times \left ( H_{kernel}-1 \right )-1}{b}+1\right \rfloor\\W_{out}=\left \lfloor \frac{W_{in}+padding\left [ 2 \right ]+padding\left [ 3 \right ]-dilation\left [ 1 \right ]\times \left ( W_{kernel}-1 \right )-1}{b}+1\right \rfloor\end{aligned}\end{align} \]</div>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(input\)</span> is an op whose result shape is of 4D. Shape is <span class="math notranslate nohighlight">\(\left ( N,C_{in},H_{in},W_{in} \right )\)</span> for layout of “NCHW” and <span class="math notranslate nohighlight">\(\left ( N,H_{in},W_{in},C_{in} \right )\)</span> for “NHWC”. Required.</p></li>
</ul>
</dd>
<dt><strong>Parameters:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(ksize\)</span> is the size of the sliding window for each dimension of input. Size is 2 for both <span class="math notranslate nohighlight">\(H_{kernel}\)</span> and <span class="math notranslate nohighlight">\(W_{kernel}\)</span>. Required.</p></li>
<li><p><span class="math notranslate nohighlight">\(ceil\_mode\)</span> whether to use ceil or floor (default) to compute the output shape. Default: false.</p></li>
<li><p><span class="math notranslate nohighlight">\(return\_indices\)</span> if true, will return the max indices along with the outputs. Default: false.</p></li>
<li><p><span class="math notranslate nohighlight">\(auto\_pad\)</span> is a string for automatically padding. If it sets as the default value, explicit padding is used. Default: “NOTSET”.</p></li>
<li><p><span class="math notranslate nohighlight">\(layout\)</span> is a string for data format, “NCHW” or “NHWC”. Default: “NHWC”.</p></li>
<li><p><span class="math notranslate nohighlight">\(stride\)</span> is the stride of the sliding window for each dimension of input. Size is 2 for both <span class="math notranslate nohighlight">\(H_{in}\)</span> and <span class="math notranslate nohighlight">\(W_{in}\)</span>. Default: [1, 1].</p></li>
<li><p><span class="math notranslate nohighlight">\(padding\)</span> specifies the amount of zero padding to be applied to the base area. Size is 4 for <span class="math notranslate nohighlight">\(\left [ top,bottom,left,right \right ]\)</span>. Default: [0, 0, 0, 0].</p></li>
<li><p><span class="math notranslate nohighlight">\(dilation\)</span> controls the spacing between the kernel points. It is harder to describe, but this <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what dilation does. Size is 2 for both <span class="math notranslate nohighlight">\(H_{kernel}\)</span> and <span class="math notranslate nohighlight">\(W_{kernel}\)</span>. Default: [1, 1].</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> of max pooling with shape of <span class="math notranslate nohighlight">\(\left ( N,C,H_{out},W_{out} \right )\)</span> for layout of “NCHW” and <span class="math notranslate nohighlight">\(\left ( N,H_{out},W_{out},C \right )\)</span> for “NHWC”.</p></li>
<li><p><span class="math notranslate nohighlight">\(indices\)</span> is an optional output which will present if return_indices is true. The dimensions of indices are the same as result. The values in indices are the indices of the selected values during pooling.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span>            <span class="c1"># input</span>
<span class="gp">&gt;&gt;&gt; </span>                      <span class="n">ksize</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                      <span class="n">ceil_mode</span><span class="o">=</span><span class="n">false</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                      <span class="n">return_indices</span><span class="o">=</span><span class="n">false</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                      <span class="n">layout</span><span class="o">=</span><span class="s2">&quot;NHWC&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                      <span class="n">stride</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                      <span class="n">padding</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="notequal">
<h2>NotEqual<a class="headerlink" href="#notequal" title="Permalink to this headline">¶</a></h2>
<p>Returns the truth value of (x != y) element-wise.</p>
<p>It supports Numpy-style broadcasting, for more details please check the <a class="reference external" href="https://numpy.org/doc/stable/user/basics.broadcasting.html">doc</a>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}not\_equal(x_{i}, y_{i})=\begin{cases}
false &amp; \text{ if } x_{i}=y_{i} \\
true &amp; \text{ if } x_{i}\neq y_{i}
\end{cases}\end{split}\]</div>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is the first input op.</p></li>
<li><p><span class="math notranslate nohighlight">\(y\)</span> is the second input op.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with broadcasting shape of the inputs and data type of bool.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">x_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [False, True, True]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="prelu">
<h2>PRelu<a class="headerlink" href="#prelu" title="Permalink to this headline">¶</a></h2>
<p>PRelu takes input data (Tensor) and slope tensor as input, and produces one output data (Tensor) where the below function <span class="math notranslate nohighlight">\(prelu(x_{i})\)</span> is applied to the data tensor elementwise.</p>
<div class="math notranslate nohighlight">
\[\begin{split}prelu(x_{i})=\begin{cases}
x_{i} &amp; \text{ if } x_{i}&gt; 0 \\
slope_{i}x_{i} &amp; \text{ if } x_{i}\leq  0
\end{cases}\end{split}\]</div>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is the input op.</p></li>
<li><p><span class="math notranslate nohighlight">\(slope\)</span> is the slope op. The shape of slope can be smaller then first input <span class="math notranslate nohighlight">\(x\)</span>; if so, its shape must be unidirectional broadcastable to <span class="math notranslate nohighlight">\(x\)</span>.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> same size and data type as <span class="math notranslate nohighlight">\(x\)</span>.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">slope_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">x_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">slope</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">slope_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">PRelu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">slope</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [0.1, 0.4, 0.9]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="reciprocal">
<h2>Reciprocal<a class="headerlink" href="#reciprocal" title="Permalink to this headline">¶</a></h2>
<p>Computes the reciprocal of x element-wise.</p>
<div class="math notranslate nohighlight">
\[reciprocal\left ( x \right )=\frac{1}{x}\]</div>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is an op whose result shape is <span class="math notranslate nohighlight">\((*)\)</span>, where <span class="math notranslate nohighlight">\(*\)</span> means any number of dimensions.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with shape of <span class="math notranslate nohighlight">\((*)\)</span>, same as the input.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Reciprocal</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [-2.5, -5., 10., 3.33333333]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="reducel2">
<h2>ReduceL2<a class="headerlink" href="#reducel2" title="Permalink to this headline">¶</a></h2>
<p>Computes the L2 norm of the input tensor’s element along the provided axis. The resulting tensor has the same rank as the input if keepdims is true. If keepdims is false, the resulting tensor has the reduced dimension pruned.</p>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is an op whose result shape is <span class="math notranslate nohighlight">\((*)\)</span>, where <span class="math notranslate nohighlight">\(*\)</span> means any number of dimensions.</p></li>
</ul>
</dd>
<dt><strong>Parameters:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(keepdims\)</span> is an optional bool. If true, keep these reduced dimensions and the length is 1. If false, don’t keep these dimensions. Default: False.</p></li>
<li><p><span class="math notranslate nohighlight">\(axis\)</span> is the dimensions along which the reduce is performed. If empty, reduce all elements of <span class="math notranslate nohighlight">\(x\)</span> and return a scalar, otherwise must be in the range <span class="math notranslate nohighlight">\([-R, R)\)</span>, where <span class="math notranslate nohighlight">\(R\)</span> is <span class="math notranslate nohighlight">\(Rank(x)\)</span>. If <span class="math notranslate nohighlight">\(axis[i]&lt; 0\)</span>, the dimension to reduce is <span class="math notranslate nohighlight">\(R + axis[i]\)</span>. Default: empty.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with the same data type of the input and the reduced shape.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">]],</span> <span class="p">[[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">],</span> <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">]],</span> <span class="p">[[</span><span class="mf">9.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">],</span> <span class="p">[</span><span class="mf">11.</span><span class="p">,</span> <span class="mf">12.</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="c1"># shape: [3, 2, 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">ReduceL2</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [[[2.23606798], [5.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#          [[7.81024968], [10.63014581]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#          [[13.45362405], [16.2788206 ]]]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="reducemax">
<h2>ReduceMax<a class="headerlink" href="#reducemax" title="Permalink to this headline">¶</a></h2>
<p>Computes the max of the input tensor’s element along the provided axis. The resulting tensor has the same rank as the input if keepdims is true. If keepdims is false, the resulting tensor has the reduced dimension pruned.</p>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is an op whose result shape is <span class="math notranslate nohighlight">\((*)\)</span>, where <span class="math notranslate nohighlight">\(*\)</span> means any number of dimensions.</p></li>
</ul>
</dd>
<dt><strong>Parameters:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(keepdims\)</span> is an optional bool. If true, keep these reduced dimensions and the length is 1. If false, don’t keep these dimensions. Default: False.</p></li>
<li><p><span class="math notranslate nohighlight">\(axis\)</span> is the dimensions along which the reduce is performed. If empty, reduce all elements of <span class="math notranslate nohighlight">\(x\)</span> and return a scalar, otherwise must be in the range <span class="math notranslate nohighlight">\([-R, R)\)</span>, where <span class="math notranslate nohighlight">\(R\)</span> is <span class="math notranslate nohighlight">\(Rank(x)\)</span>. If <span class="math notranslate nohighlight">\(axis[i]&lt; 0\)</span>, the dimension to reduce is <span class="math notranslate nohighlight">\(R + axis[i]\)</span>. Default: empty.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with the same data type of the input and the reduced shape.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">40</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">55</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="c1"># shape: [3, 2, 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">ReduceMax</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [[20., 2.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#          [40., 2.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#          [60., 2.]]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="reducemean">
<h2>ReduceMean<a class="headerlink" href="#reducemean" title="Permalink to this headline">¶</a></h2>
<p>Computes the mean of the input tensor’s element along the provided axis. The resulting tensor has the same rank as the input if keepdims is true. If keepdims is false, the resulting tensor has the reduced dimension pruned.</p>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is an op whose result shape is <span class="math notranslate nohighlight">\((*)\)</span>, where <span class="math notranslate nohighlight">\(*\)</span> means any number of dimensions.</p></li>
</ul>
</dd>
<dt><strong>Parameters:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(keepdims\)</span> is an optional bool. If true, keep these reduced dimensions and the length is 1. If false, don’t keep these dimensions. Default: False.</p></li>
<li><p><span class="math notranslate nohighlight">\(axis\)</span> is the dimensions along which the reduce is performed. If empty, reduce all elements of <span class="math notranslate nohighlight">\(x\)</span> and return a scalar, otherwise must be in the range <span class="math notranslate nohighlight">\([-R, R)\)</span>, where <span class="math notranslate nohighlight">\(R\)</span> is <span class="math notranslate nohighlight">\(Rank(x)\)</span>. If <span class="math notranslate nohighlight">\(axis[i]&lt; 0\)</span>, the dimension to reduce is <span class="math notranslate nohighlight">\(R + axis[i]\)</span>. Default: empty.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with the same data type of the input and the reduced shape.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">40</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">55</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="c1"># shape: [3, 2, 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [[[18.25]]]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="reducemin">
<h2>ReduceMin<a class="headerlink" href="#reducemin" title="Permalink to this headline">¶</a></h2>
<p>Computes the min of the input tensor’s element along the provided axis. The resulting tensor has the same rank as the input if keepdims is true. If keepdims is false, the resulting tensor has the reduced dimension pruned.</p>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is an op whose result shape is <span class="math notranslate nohighlight">\((*)\)</span>, where <span class="math notranslate nohighlight">\(*\)</span> means any number of dimensions.</p></li>
</ul>
</dd>
<dt><strong>Parameters:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(keepdims\)</span> is an optional bool. If true, keep these reduced dimensions and the length is 1. If false, don’t keep these dimensions. Default: False.</p></li>
<li><p><span class="math notranslate nohighlight">\(axis\)</span> is the dimensions along which the reduce is performed. If empty, reduce all elements of <span class="math notranslate nohighlight">\(x\)</span> and return a scalar, otherwise must be in the range <span class="math notranslate nohighlight">\([-R, R)\)</span>, where <span class="math notranslate nohighlight">\(R\)</span> is <span class="math notranslate nohighlight">\(Rank(x)\)</span>. If <span class="math notranslate nohighlight">\(axis[i]&lt; 0\)</span>, the dimension to reduce is <span class="math notranslate nohighlight">\(R + axis[i]\)</span>. Default: empty.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with the same data type of the input and the reduced shape.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">40</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">55</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="c1"># shape: [3, 2, 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">ReduceMin</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [[[5., 1.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#          [[30., 1.]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#          [[55., 1.]]]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="reduceprod">
<h2>ReduceProd<a class="headerlink" href="#reduceprod" title="Permalink to this headline">¶</a></h2>
<p>Computes the product of the input tensor’s element along the provided axis. The resulting tensor has the same rank as the input if keepdims is true. If keepdims is false, the resulting tensor has the reduced dimension pruned.</p>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is an op whose result shape is <span class="math notranslate nohighlight">\((*)\)</span>, where <span class="math notranslate nohighlight">\(*\)</span> means any number of dimensions.</p></li>
</ul>
</dd>
<dt><strong>Parameters:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(keepdims\)</span> is an optional bool. If true, keep these reduced dimensions and the length is 1. If false, don’t keep these dimensions. Default: False.</p></li>
<li><p><span class="math notranslate nohighlight">\(axis\)</span> is the dimensions along which the reduce is performed. If empty, reduce all elements of <span class="math notranslate nohighlight">\(x\)</span> and return a scalar, otherwise must be in the range <span class="math notranslate nohighlight">\([-R, R)\)</span>, where <span class="math notranslate nohighlight">\(R\)</span> is <span class="math notranslate nohighlight">\(Rank(x)\)</span>. If <span class="math notranslate nohighlight">\(axis[i]&lt; 0\)</span>, the dimension to reduce is <span class="math notranslate nohighlight">\(R + axis[i]\)</span>. Default: empty.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with the same data type of the input and the reduced shape.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="c1"># shape: [3, 2, 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">ReduceProd</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: [[3., 8.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#          [35., 48.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#          [99., 120.]]</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="reducesum">
<h2>ReduceSum<a class="headerlink" href="#reducesum" title="Permalink to this headline">¶</a></h2>
<p>Computes the sum of the input tensor’s element along the provided axis. The resulting tensor has the same rank as the input if keepdims is true. If keepdims is false, the resulting tensor has the reduced dimension pruned.</p>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is an op whose result shape is <span class="math notranslate nohighlight">\((*)\)</span>, where <span class="math notranslate nohighlight">\(*\)</span> means any number of dimensions.</p></li>
</ul>
</dd>
<dt><strong>Parameters:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(keepdims\)</span> is an optional bool. If true, keep these reduced dimensions and the length is 1. If false, don’t keep these dimensions. Default: False.</p></li>
<li><p><span class="math notranslate nohighlight">\(axis\)</span> is the dimensions along which the reduce is performed. If empty, reduce all elements of <span class="math notranslate nohighlight">\(x\)</span> and return a scalar, otherwise must be in the range <span class="math notranslate nohighlight">\([-R, R)\)</span>, where <span class="math notranslate nohighlight">\(R\)</span> is <span class="math notranslate nohighlight">\(Rank(x)\)</span>. If <span class="math notranslate nohighlight">\(axis[i]&lt; 0\)</span>, the dimension to reduce is <span class="math notranslate nohighlight">\(R + axis[i]\)</span>. Default: empty.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with the same data type of the input and the reduced shape.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="c1"># shape: [3, 2, 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result: 78.</span>
</pre></div>
</div>
</dd>
</dl>
</div>
<div class="section" id="square">
<h2>Square<a class="headerlink" href="#square" title="Permalink to this headline">¶</a></h2>
<p>Applies the square function element-wise:</p>
<div class="math notranslate nohighlight">
\[square\left ( x \right )=x^{2}\]</div>
<dl>
<dt><strong>Inputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span> is an op whose result shape is <span class="math notranslate nohighlight">\((*)\)</span>, where <span class="math notranslate nohighlight">\(*\)</span> means any number of dimensions.</p></li>
</ul>
</dd>
<dt><strong>Outputs:</strong></dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(result\)</span> with shape of <span class="math notranslate nohighlight">\((*)\)</span>, same as the input.</p></li>
</ul>
</dd>
<dt><strong>Examples:</strong></dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Const</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">hb</span><span class="o">.</span><span class="n">Square</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="tops_graph_compiler.html" class="btn btn-neutral float-right" title="TopsGraph Compiler" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="meta_operation_semantics.html" class="btn btn-neutral" title="Meta Operation Semantics" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, HLIR Builder Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Client Operation Semantics</a><ul>
<li><a class="reference internal" href="#argmax">ArgMax</a></li>
<li><a class="reference internal" href="#argmin">ArgMin</a></li>
<li><a class="reference internal" href="#argsort">ArgSort</a></li>
<li><a class="reference internal" href="#conv2d">Conv2D</a></li>
<li><a class="reference internal" href="#conv2dtranspose">Conv2DTranspose</a></li>
<li><a class="reference internal" href="#equal">Equal</a></li>
<li><a class="reference internal" href="#flatten">Flatten</a></li>
<li><a class="reference internal" href="#greater">Greater</a></li>
<li><a class="reference internal" href="#greaterequal">GreaterEqual</a></li>
<li><a class="reference internal" href="#hardsigmoid">HardSigmoid</a></li>
<li><a class="reference internal" href="#hardswish">HardSwish</a></li>
<li><a class="reference internal" href="#less">Less</a></li>
<li><a class="reference internal" href="#lessequal">LessEqual</a></li>
<li><a class="reference internal" href="#maxpool2d">MaxPool2D</a></li>
<li><a class="reference internal" href="#notequal">NotEqual</a></li>
<li><a class="reference internal" href="#prelu">PRelu</a></li>
<li><a class="reference internal" href="#reciprocal">Reciprocal</a></li>
<li><a class="reference internal" href="#reducel2">ReduceL2</a></li>
<li><a class="reference internal" href="#reducemax">ReduceMax</a></li>
<li><a class="reference internal" href="#reducemean">ReduceMean</a></li>
<li><a class="reference internal" href="#reducemin">ReduceMin</a></li>
<li><a class="reference internal" href="#reduceprod">ReduceProd</a></li>
<li><a class="reference internal" href="#reducesum">ReduceSum</a></li>
<li><a class="reference internal" href="#square">Square</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
         <script src="_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
         <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for HLIR Builder</p>
          <!--<a class="with-right-arrow" href="https://www.enflame-tech.com">View Docs</a> -->
          <a class="with-right-arrow">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <!--<a class="with-right-arrow" href="https://www.enflame-tech.com">View Tutorials</a> -->
          <a class="with-right-arrow">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <!--<a class="with-right-arrow" href="https://www.enflame-tech.com">View Resources</a> -->
          <a class="with-right-arrow">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <!--<div class="footer-logo-wrapper">
        <a href="https://www.enflame-tech.com" class="footer-logo"></a>
      </div>-->

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <!--<li><a href="https://www.enflame-tech.com">Get Started</a></li> -->
            <li><a>Get Started</a></li>
            <!--<li><a href="https://www.enflame-tech.com">Features</a></li> -->
            <li><a>C++ API</a></li>
            <!--<li><a href="https://www.enflame-tech.com">Ecosystem</a></li> -->
            <li><a>Python API</a></li>
            <!--<li><a href="https://www.enflame-tech.com">Blog</a></li> -->
            <li><a>Tutorials</a></li>
            <!--<li><a href="https://www.enflame-tech.com">Contributing</a></li> -->
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <!--<li class="list-title"><a href="https://www.enflame-tech.com">Resources</a></li> -->
            <li class="list-title"><a>Contributing</a></li>
            <!--<li><a href="https://www.enflame-tech.com">Tutorials</a></li> -->
            <!--<li><a href="https://www.enflame-tech.com">Docs</a></li> -->
            <li><a>Applications</a></li>
            <!--<li><a href="https://www.enflame-tech.com" target="_blank">Discuss</a></li> -->
            <li><a>Discuss</a></li>
            <!--<li><a href="https://www.enflame-tech.com" target="_blank">Github Issues</a></li> -->
            <li><a>Github Issues</a></li>
            <!--<li><a href="https://www.enflame-tech.com" target="_blank">Brand Guidelines</a></li> -->
          </ul>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>